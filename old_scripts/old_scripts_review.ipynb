{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7b84d2",
   "metadata": {},
   "source": [
    "## Original script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ddc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import os \n",
    "from pathlib import Path\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import scipy as stats\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.stats import chi2\n",
    "from sklearn.covariance import MinCovDet\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Step 1: Filter out the non-protein coding genes from GTEX\n",
    "\n",
    "Remove genes from the data which do not encode a protein and to log transform the gene expression matrix.\n",
    "\n",
    "Source:  https://www.genenames.org/download/statistics-and-files/ retrieved January 19 2022 </p>\n",
    "Selected 19208 protein coding genes as txt file </p>\n",
    "Input: protein coding gene list with current list of know protein coding genes\n",
    "       GTEX matrix contain at total of 56200 genes and 17382 samples \n",
    "\n",
    "Output: \n",
    "A matrix containing on the ENSMBL description and only the genes that were in the intersection of the protein coding genes and GTEx matrix. \n",
    "A dictionary from ENSMBL to description.\n",
    "'''\n",
    "\n",
    "def filter_non_protein_coding(HGNC_list, GTEx_tpm):\n",
    "    \n",
    "    PCG_list.rename(columns={'symbol':'PCG Symbols'},inplace=True)\n",
    "    PCG_list = PCG_list['PCG Symbols'].tolist()\n",
    "\n",
    "    matrix_pcg_df = GTEx_tpm[GTEx_tpm['Description'].isin(PCG_list)]\n",
    "    pcg_dictionary = matrix_pcg_df[['Name','Description']]\n",
    "    pcg_dictionary = pcg_dictionary.set_index('Name')\n",
    "    \n",
    "    matrix_pcg_df =matrix_pcg_df.drop(['Description'], axis=1)\n",
    "    matrix_pcg_df.set_index('Name',inplace=True)\n",
    "    \n",
    "    log_transform(matrix_pcg_df)\n",
    "    \n",
    "    return pcg_dictionary,matrix_pcg_df\n",
    "\n",
    "\n",
    "def log_transform(matrix_pcg_df):\n",
    "    matrix_pcg_df = matrix_pcg_df +1\n",
    "    matrix_pcg_df = np.log2(matrix_pcg_df)\n",
    "    return matrix_pcg_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Step 2: Sample attributes\n",
    "1. Filter out death types for both samples and attributes \n",
    "2. Filter out low RIN\n",
    "\n",
    "Input: Sample annotations (attributes csv file),\n",
    "       Subject phenotypes (pheno csv file),\n",
    "       GTEX matrix\n",
    "'''\n",
    "\n",
    "def setup_attributes (pheno_df, attributes_df, matrix_pcg_df):\n",
    "    # Filter death types\n",
    "    pheno_a = pheno[(pheno['DTHHRDY'] > 0) & (pheno['DTHHRDY'] < 3)]\n",
    "    important_attributes = attributes[['SMRIN','SMTSISCH','SMTSD','SMGEBTCH']]\n",
    "    important_attributes = important_attributes.assign(SUBJID = '')\n",
    "    sampids = important_attributes.index.tolist()\n",
    "    for i in range(important_attributes.shape[0]):\n",
    "        x = sampids[i].split('-')\n",
    "        xx = ''\n",
    "        xx = xx+x[0]+'-'+x[1]\n",
    "        important_attributes.iloc[i,4] = xx\n",
    "    important_attributes.dropna(inplace = True)\n",
    "    \n",
    "    # Filter RIN\n",
    "    important_attributes = important_attributes.drop(important_attributes[important_attributes['SMRIN'] <5.7].index, axis = 0)\n",
    "\n",
    "    new_df  =pd.merge(important_attributes.reset_index(), pheno_a, on=['SUBJID'], how='inner')\n",
    "    new_df =new_df.set_index('SAMPID')\n",
    "    pheno_aa = new_df.dropna(axis=0,how='any')\n",
    "    pheno_aa['AGE'] = pheno_aa['AGE'].str.split('-', 1).str[0].astype(int)\n",
    "    \n",
    "    aa_samples = pheno_aa.index.tolist()\n",
    "    matrix_pcg_aa = matrix_pcg.loc[:, matrix_pcg.columns.isin(aa_samples)]\n",
    "    aa_matrix_samples = matrix_pcg_aa.columns.to_list()\n",
    "    sample_attributes = new_df.loc[new_df.index.isin(aa_matrix_samples),:]\n",
    "    return matrix_pcg_aa, sample_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d24eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Step 3: Create data for tissues\n",
    "'''\n",
    "def create_data_for_tissue (sample_attributes, matrix_pcg_aa, number_of_tissues = 13, length_threshold = 100):\n",
    "\n",
    "    samples = sample_attributes\n",
    "    sample_tissues = samples['SMTSD'].value_counts()\n",
    "\n",
    "    tissues = sample_tissues[sample_tissues>100].index.to_list()\n",
    "    pcg = matrix_pcg_aa\n",
    "\n",
    "    for i in range(number_of_tissues):\n",
    "\n",
    "        current_tissue = tissues[i]\n",
    "        current_tissue = current_tissue[:length_threshold]\n",
    "\n",
    "        tissue_type = current_tissue[:length_threshold]\n",
    "\n",
    "        tissue_samples = samples[samples['SMTSD'].str.startswith(tissue_type)]\n",
    "        tissue_ids = tissue_samples.index.tolist()\n",
    "\n",
    "        print(pheno.shape)\n",
    "        matrix = pcg[tissue_ids]\n",
    "        \n",
    "        tissue_samples.to_csv(f'{current_tissue}/tissue_sample_DT1DT2.csv')\n",
    "        matrix.to_csv(f'{current_tissue}/tissue_matrix_DT1DT2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8826424",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "'''\n",
    "Step 4: Process tissue data\n",
    "\n",
    "1. Filter genes with low expression and low veriabilty \n",
    "2. Remove outliers\n",
    "3. Quantile normalization\n",
    "4. Make modifications to phenotype attributes\n",
    "'''\n",
    "\n",
    "def create_exclusion_list(genes, values, limit_val):\n",
    "    exclude_genes_list = []\n",
    "    for i in range(len(genes)):\n",
    "        if (values[i] < limit_val):\n",
    "            exclude_genes_list.append(genes[i])\n",
    "    return exclude_genes_list \n",
    "\n",
    "\n",
    "# filter Genes with zero variance  \n",
    "def filter_genes (tissue_matrix, sample_attributes):\n",
    "    sample_attributes['AGE'] = sample_attributes['AGE'].str.split('-', 1).str[0].astype(int)\n",
    "\n",
    "    print(str(len(tissue_matrix[(tissue_matrix.T <np.log2(0.1+1) ).sum()>0.2*tissue_matrix.shape[1]])) + \" genes filtered out\")\n",
    "    df1 = tissue_matrix[(tissue_matrix.T <np.log2(0.1+1) ).sum()<0.2*tissue_matrix.shape[1]] \n",
    "    df1 = df1.T\n",
    "    variability_df = df1.var()\n",
    "    print(variability_df)\n",
    "    gene_names = variability_df.index.tolist()\n",
    "    gene_vars = variability_df.tolist()\n",
    "\n",
    "    excluded_list = create_exclusion_list(gene_names,gene_vars,variability_threshold)\n",
    "    print('length of excluded list:' + str(len(excluded_list)))\n",
    "\n",
    "    df1 = df1.drop(excluded_list, axis=1)\n",
    "    sample1 = sample_attributes.copy(deep=True)\n",
    "    return df1, sample1\n",
    "  \n",
    "\n",
    "#remove outlier samples using mahanalobis on specific pca\n",
    "def sample_outliers_df(matrix_val, sample_val):\n",
    "    print('sample outliers')\n",
    "    print(matrix_val.shape) # rows are genes col are sampels\n",
    "    display(matrix_val.head())\n",
    "    display(sample_val.head())\n",
    "    print('isna')\n",
    "    print(matrix_val.isna().sum())\n",
    "    matrix_val.isna().sum()\n",
    "    matrix_val.fillna(value=0.0000001,inplace=True)\n",
    "    print(matrix_val.isna().sum())\n",
    "    \n",
    "    sample_cum_pca = []\n",
    "    gene_cum_pca = []\n",
    "    current_sum = 0\n",
    "    print(\"removing outliers\")\n",
    "    print(matrix_val.shape)\n",
    "    #pca_gene = PCA(n_components=gene_pca_components)\n",
    "    pca_gene = TruncatedSVD(n_components=20, random_state=1001)\n",
    "    pca_gene.fit(matrix_val)\n",
    "    components =  pca_gene.components_\n",
    "    components = components.T\n",
    "    print(type(components))\n",
    "    print('components shape')\n",
    "    print(components.shape)\n",
    "    comp_df = pd.DataFrame(data=components)\n",
    "    \n",
    "    samples_before_outlier_removal = matrix_val.columns.tolist()\n",
    "    print(samples_before_outlier_removal)\n",
    "    samples_to_remove = []\n",
    "    \n",
    "     \n",
    "    # Covariance matrix\n",
    "    covariance  = np.cov(components , rowvar=False)\n",
    "    # Covariance matrix power of -1\n",
    "    covariance_pm1 = np.linalg.matrix_power(covariance, -1)\n",
    "    # Center point\n",
    "    centerpoint = np.mean(components , axis=0)\n",
    "    \n",
    "    # Distances between center point and \n",
    "    distances = []\n",
    "    for i, val in enumerate(components):\n",
    "        p1 = val\n",
    "        \n",
    "        p2 = centerpoint\n",
    "       \n",
    "        distance = (p1-p2).T.dot(covariance_pm1).dot(p1-p2)\n",
    "        distances.append(distance)\n",
    "    distances = np.array(distances)\n",
    "\n",
    "    \n",
    "    # Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers \n",
    "    cutoff = chi2.ppf(0.99, components.shape[1]*2)\n",
    "    print('distances')\n",
    "    print(distances)\n",
    "    print('cutoff')\n",
    "    print(cutoff)\n",
    "    display(matrix_val.head())\n",
    "    print(matrix_val.shape)\n",
    "    display(sample_val.head())\n",
    "    print(sample_val.shape)\n",
    "\n",
    "    # Index of outliers\n",
    "    outlierIndexes = np.where(distances > cutoff )\n",
    "    outlierIndexes = list(outlierIndexes[0])\n",
    "\n",
    "    print('--- Index of Outliers ----')\n",
    "    print(outlierIndexes)\n",
    "    print(type(outlierIndexes))\n",
    "    print(len(outlierIndexes))\n",
    "    for q2 in range(len(outlierIndexes)):\n",
    "        print(outlierIndexes[q2])\n",
    "        samples_to_remove.append(samples_before_outlier_removal[q2])\n",
    "    print(samples_to_remove)\n",
    "    \n",
    "    df = pd.DataFrame(data=components)\n",
    "    display(df.head())\n",
    "    \n",
    "    print('dropping outliers')\n",
    "    print('matrix shape before drop')\n",
    "    print(matrix_val.shape)\n",
    "    matrix_val = matrix_val.drop(labels = samples_to_remove, axis=1)\n",
    "    print('matrix shape after drop')\n",
    "    print(matrix_val.shape)\n",
    "    print('sample shape before drop')\n",
    "    print(sample_val.shape)\n",
    "    sample_val = sample_val.drop(labels = samples_to_remove, axis=0)\n",
    "    print('sample shape after drop')\n",
    "    print(sample_val.shape)\n",
    "\n",
    "    return matrix_val, sample_val\n",
    "\n",
    "\n",
    "def quantile_normalize(matrix_val):\n",
    "    df = matrix_val\n",
    "    df_image1 = df.iloc[:,0:3]\n",
    "    print('df image before quantile normalization: '+str(df_image1.shape))\n",
    "    sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "    ax = sns.boxplot(data=df_image1, linewidth=2.5).set(title='Before quantile')\n",
    "    plt.savefig('before_quantile.png')\n",
    "    plt.show()\n",
    "    print(matrix_val.shape)\n",
    "    display(df_image1.head(2))\n",
    "\n",
    "    df_sorted = pd.DataFrame(np.sort(df.values,\n",
    "                                     axis=0), \n",
    "                             index=df.index, \n",
    "                             columns=df.columns)\n",
    "    df_mean = df_sorted.mean(axis=1)\n",
    "    df_mean.index = np.arange(1, len(df_mean) + 1)\n",
    "    df_qn =df.rank(method=\"min\").stack().astype(int).map(df_mean).unstack()\n",
    "    \n",
    "    \n",
    "    df_image2 = df_qn.iloc[:,0:3]\n",
    "    print('df image after quantile normalization: '+str(df_image2.shape))\n",
    "    sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "    ax = sns.boxplot(data=df_image2, linewidth=2.5).set(title='After quantile')\n",
    "    plt.savefig('after_quantile.png')\n",
    "    plt.show()\n",
    "    display(df_image2.head(2))\n",
    "    \n",
    "    return df_qn\n",
    "\n",
    "\n",
    "\n",
    "def process_tissue (tissue_matrix , sample_attributes, current_tissue):\n",
    "\n",
    "    # 1.filter genes with low expression and low veriabilty\n",
    "    print(\"---1.filtering---\")\n",
    "    ###remove genes that have value less than 0.1 transcripts per million (TPM) in more than 80% of the samples\n",
    "    df1, sample1 = filter_genes(tissue_matrix, sample_attributes)\n",
    "\n",
    "\n",
    "    # 2. remove outliers\n",
    "    print(\"---2.remove outliers---\")\n",
    "    df2, sample2 = sample_outliers_df(df1.T,sample1)\n",
    "\n",
    "    # 3. quantile normalization\n",
    "    print(\"---3.quantile normalization---\")\n",
    "\n",
    "    df3 = quantile_normalize(df2)\n",
    "\n",
    "    # 4. make modifications to phenotype attributes\n",
    "\n",
    "    sample3 = sample2.copy(deep=True)\n",
    "    agegroup = sample3['AGE'].tolist()\n",
    "    sample3['AGE'] = [elem[:2] for elem in agegroup]\n",
    "    SMGEBTCH= sample3['SMGEBTCH'].value_counts(normalize=False, sort=True)\n",
    "    SMGEBTCH_names = SMGEBTCH.index.tolist()\n",
    "    SMGEBTCH_value =  SMGEBTCH.tolist()\n",
    "    SMGEBTCH_new_list  = []\n",
    "    for i in range (len(SMGEBTCH_names)):\n",
    "        if SMGEBTCH_value[i] > 1:\n",
    "            SMGEBTCH_new_list.append(SMGEBTCH_names[i])\n",
    "\n",
    "    batches = []\n",
    "    for i in range(sample3.shape[0]):\n",
    "\n",
    "        if sample3['SMGEBTCH'].iloc[i] in SMGEBTCH_new_list:\n",
    "            batches.append(sample3['SMGEBTCH'].iloc[i])\n",
    "        else:\n",
    "            batches.append('ASINGLETON_SMGEBTCH')\n",
    "\n",
    "    sample3['SMGEBTCH'] = batches\n",
    "\n",
    "    SMGEBTCH = pd.get_dummies(sample4['SMGEBTCH'],drop_first=True)\n",
    "    sample4.drop(['SMTSD','SMGEBTCH','SUBJID'], axis=1, inplace=True)\n",
    "\n",
    "    new_sample4 = [sample3, SMGEBTCH]\n",
    "    sample5 = pd.concat(new_sample4 , join='inner', axis=1)\n",
    "    \n",
    "          \n",
    "    df3.to_csv(f'{current_tissue}/tissue_matrix_preReg.csv')\n",
    "    sample5.to_csv(f'{current_tissue}/tissue_sample_preReg.csv')\n",
    "    return df3, sample5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eb05d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Step 5: Confouding factors\n",
    "'''\n",
    "\n",
    "def regress_confounding (matrix , sample, current_tissue):\n",
    "    matrix = matrix.T # sampels X genes \n",
    "    sk_resid_mat=matrix.copy(deep=True) # sampels X genes \n",
    "    for col in sk_resid_mat.columns: # loop on genes\n",
    "        sk_resid_mat[col].values[:] = 0\n",
    "\n",
    "    age =  sample['AGE']\n",
    "    death_type =  sample['DTHHRDY']\n",
    "    \n",
    "    x = sample.drop(['AGE', 'SMRIN', 'DTHHRDY'], axis =1)\n",
    "    \n",
    "    for i in range(matrix.shape[1]): # loop on cols = genes\n",
    "        reg = LinearRegression()\n",
    "        y = matrix.iloc[:,i] # all sampels, one gene\n",
    "        reg.fit(x,y)\n",
    "        prediction = reg.predict(x)\n",
    "        coefs = reg.coef_.tolist()\n",
    "        sk_resid_mat.iloc[:,i] = y - prediction # replace gene i with residual\n",
    "              \n",
    "    feature_names = sample.columns.tolist()\n",
    "\n",
    "    sk_resid_mat_norm = quantile_normalize(sk_resid_mat.T)\n",
    "    sk_resid_mat_norm.to_csv(f'{current_tissue}/sk_residual_matrix_w_const.csv')\n",
    "    return sk_resid_mat_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b432a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "'''\n",
    "Step 6: split age groups\n",
    "'''\n",
    "\n",
    "def split_age_group(matrix, sample_processed, current_tissue)\n",
    "\n",
    "    matrix = matrix.T\n",
    "    pool_of_samples = samples.index.tolist() \n",
    "    \n",
    "    young_sample =  sample[sample['AGE'] < 60]\n",
    "    old_sample =    sample[sample['AGE'] >= 60]  \n",
    "    \n",
    "    young_list =  young_sample.index.tolist()\n",
    "    old_list =  old_sample.index.tolist()\n",
    "    \n",
    "    young_matrix = matrix[matrix.columns.intersection(young_list)]\n",
    "    young_matrix = young_matrix.T\n",
    "   \n",
    "    old_matrix = matrix[matrix.columns.intersection(old_list)]\n",
    "    old_matrix =  old_matrix.T\n",
    "    \n",
    "    young_sample.to_csv(f'{current_tissue}/young_sample.csv')\n",
    "    young_matrix.to_csv(f'{current_tissue}/young_matrix.csv')\n",
    "    old_sample.to_csv(f'{current_tissue}/old_sample.csv')\n",
    "    old_matrix.to_csv(f'{current_tissue}/old_matrix.csv')\n",
    "    \n",
    "    return young_sample, young_matrix, old_sample, old_matrix\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1933f34",
   "metadata": {},
   "source": [
    "# Reviewing the old scripts\n",
    "\n",
    "## GTEx_dataPrep.py\n",
    "a. This script starts with the main function that loads the GTEx data, HGNC gene names, phenotype data, and attribute data.\n",
    "b. Then it initializes some constant variables and tissues target list.\n",
    "\n",
    " ```python\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    GTEx_tpm = pd.read_csv('GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct', sep='\\t',skiprows=2)\n",
    "    HGNC_list = pd.read_csv('ProteinCodingGenesRetreived01192022.csv', usecols=[0,1,2,3,4,5,6])\n",
    "    pheno_df = pd.read_csv('GTEx_Analysis_v8_Annotations_SubjectPhenotypesDS.csv')\n",
    "    attributes_df = pd.read_csv('GTEx_Analysis_v8_Annotations_SampleAttributesDS.csv',index_col=0)\n",
    "\n",
    "    number_of_tissues = 13\n",
    "    length_threshold = 100\n",
    "    variability_threshold = 0.02\n",
    "    sample_pca_components = 3\n",
    "    gene_pca_components = 50\n",
    "\n",
    "    tissues = ['Muscle - Skeletal',\n",
    "     'Whole Blood',\n",
    "     'Skin - Sun Exposed (Lower leg)',\n",
    "     'Skin - Not Sun Exposed (Suprapubic)',\n",
    "     'Adipose - Subcutaneous',\n",
    "     'Thyroid',\n",
    "     'Artery - Tibial',\n",
    "     'Nerve - Tibial',\n",
    "     'Lung',\n",
    "     'Brain - Cerebellum',\n",
    "     'Heart - Atrial Appendage',\n",
    "     'Brain - Cortex',\n",
    "     'Adipose - Visceral (Omentum)']\n",
    "```\n",
    "\n",
    "c. The script then calls the `filter_non_protein_coding` function with the HGNC list and the GTEx TPM data to filter out non-protein coding genes.\n",
    "\n",
    "```python\n",
    "    pcg_dictionary,matrix_pcg_df = filter_non_protein_coding(HGNC_list, GTEx_tpm)\n",
    "```\n",
    "\n",
    "d. The `filter_non_protein_coding` function filter the non-protein coding genes from the GTEx TPM data and returns a dictionary of protein coding genes and a DataFrame of the filtered matrix. But this function also includes a `log_transform` function that applies a log transformation to the matrix before returning it. Thats a bug in the original script, as the log transformation is happening again in the `main` function after the data is filtered.\n",
    "\n",
    "e. Then the script calls the `setup_attributes` function with the phenotype data, attributes data, and the filtered matrix to:\n",
    "    1. filter the death types (only 1,2)\n",
    "    2. transform the subject IDs to short IDs\n",
    "    3. filter the low quality samples (RIN < 5.7)\n",
    "    4. convert the age to numeric (60-79 to 60)\n",
    "\n",
    "f. Then the script calls the `create_data_for_tissue` function to save the data for each tissue after the processing steps.\n",
    "\n",
    "g. Then the script iterates over the list of tissues and calls the `process_tissue` function for each tissue to:\n",
    "    1. filter genes by variability threshold (and convert age to numeric again)\n",
    "    2. remove outliers from the matrix by Hotellinger's T2 test:\n",
    "\n",
    "```python\n",
    "    def sample_outliers_df(matrix_val, sample_val):\n",
    "    matrix_val.isna().sum()\n",
    "    matrix_val.fillna(value=0.0000001,inplace=True)\n",
    "    \n",
    "    sample_cum_pca = []\n",
    "    gene_cum_pca = []\n",
    "    current_sum = 0\n",
    "    #pca_gene = PCA(n_components=gene_pca_components)\n",
    "    pca_gene = TruncatedSVD(n_components=20, random_state=1001)\n",
    "    pca_gene.fit(matrix_val)\n",
    "    components =  pca_gene.components_\n",
    "    components = components.T\n",
    "    comp_df = pd.DataFrame(data=components)\n",
    "    \n",
    "    samples_before_outlier_removal = matrix_val.columns.tolist()\n",
    "    samples_to_remove = []\n",
    "    \n",
    "     \n",
    "    # Covariance matrix\n",
    "    covariance  = np.cov(components , rowvar=False)\n",
    "    # Covariance matrix power of -1\n",
    "    covariance_pm1 = np.linalg.matrix_power(covariance, -1)\n",
    "    # Center point\n",
    "    centerpoint = np.mean(components , axis=0)\n",
    "    \n",
    "    # Distances between center point and \n",
    "    distances = []\n",
    "    for i, val in enumerate(components):\n",
    "        p1 = val\n",
    "        \n",
    "        p2 = centerpoint\n",
    "       \n",
    "        distance = (p1-p2).T.dot(covariance_pm1).dot(p1-p2)\n",
    "        distances.append(distance)\n",
    "    distances = np.array(distances)\n",
    "\n",
    "    \n",
    "    # Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers \n",
    "    cutoff = chi2.ppf(0.99, components.shape[1]*2)\n",
    "\n",
    "    # Index of outliers\n",
    "    outlierIndexes = np.where(distances > cutoff )\n",
    "    outlierIndexes = list(outlierIndexes[0])\n",
    "\n",
    "    for q2 in range(len(outlierIndexes)):\n",
    "        samples_to_remove.append(samples_before_outlier_removal[q2])\n",
    "    \n",
    "    df = pd.DataFrame(data=components)\n",
    "    \n",
    "    matrix_val = matrix_val.drop(labels = samples_to_remove, axis=1)\n",
    "    sample_val = sample_val.drop(labels = samples_to_remove, axis=0)\n",
    "\n",
    "    return matrix_val, sample_val\n",
    "```\n",
    "* NOTE the script is iterating over an index from zero to the length of the outlier indexes, but it should iterate over the `outlierIndexes` list directly.\n",
    "\n",
    "$$d^2(x_i) = (x_i - \\mu)^T \\Sigma^{-1} (x_i - \\mu)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $x_i$ is sample $i$ in the PCA-reduced space\n",
    "- $\\mu$ is the mean vector across all samples\n",
    "- $\\Sigma^{-1}$ is the inverse of the covariance matrix\n",
    "\n",
    "    3. apply quantile normalization to the matrix\n",
    "    4. prepare the sample gene expression batch data for the dummy transformation (for the confounding variables)\n",
    "    5. save the processed data to a CSV file\n",
    "\n",
    "h. The script calls the `regress_confounding` function with the processed matrix and the sample data to regress out the confounding variables.\n",
    "\n",
    "```python\n",
    "def regress_confounding (matrix , sample, current_tissue):\n",
    "    matrix = matrix.T # sampels X genes \n",
    "    sk_resid_mat=matrix.copy(deep=True) # sampels X genes \n",
    "    for col in sk_resid_mat.columns: # loop on genes\n",
    "        sk_resid_mat[col].values[:] = 0\n",
    "\n",
    "    age =  sample['AGE']\n",
    "    death_type =  sample['DTHHRDY']\n",
    "    \n",
    "    x = sample.drop(['AGE', 'SMRIN', 'DTHHRDY'], axis =1)\n",
    "    \n",
    "    for i in range(matrix.shape[1]): # loop on cols = genes\n",
    "        reg = LinearRegression()\n",
    "        y = matrix.iloc[:,i] # all sampels, one gene\n",
    "        reg.fit(x,y)\n",
    "        prediction = reg.predict(x)\n",
    "        coefs = reg.coef_.tolist()\n",
    "        sk_resid_mat.iloc[:,i] = y - prediction # replace gene i with residual\n",
    "              \n",
    "    feature_names = sample.columns.tolist()\n",
    "\n",
    "    sk_resid_mat_norm = quantile_normalize(sk_resid_mat.T)\n",
    "    sk_resid_mat_norm.to_csv(f'{current_tissue}/sk_residual_matrix_w_const.csv')\n",
    "    return sk_resid_mat_norm\n",
    "```\n",
    "* NOTE the script is not dropping all the non-numeric columns from the sample data before the regression, which can lead to errors in the regression model. Also, the script is not converting the boolean columns to integers (0,1) before the regression, which can lead to errors in the regression model too.\n",
    "Also, the script is calling the `quantile_normalize` function on the residual matrix, I wonder if this is a bug or not, as the residual matrix should already be normalized.\n",
    "Finally, the script run the regression for each gene separately, which is not efficient. It would be better to run the regression in vectorized form for all genes at once.\n",
    "\n",
    "i. The script then calls the `split_age_group` function to split the matrix into age groups (around 60) and save the data for each age group.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0cb066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc13008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original script\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

"""
Test Script for Coexpression Network Analysis Pipeline
Demonstrates usage of the analysis modules with a small dataset
"""

import pandas as pd
import numpy as np
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Import custom modules
from data_reader import GTExDataReader
from preprocessing import DataPreprocessor
from network_analysis import NetworkAnalysis
from mdc_analysis import MDCAnalyzer
from visualization import NetworkVisualizer

def test_pipeline():
    """Test the complete analysis pipeline with a subset of data."""
    
    print("=" * 60)
    print("COEXPRESSION NETWORK ANALYSIS PIPELINE TEST")
    print("=" * 60)
    
    # 1. Data Loading
    print("\n1. Loading GTEx data...")
    reader = GTExDataReader()
    
    try:
        # Load a small subset for testing
        expression_df, gene_metadata = reader.read_gct_file(
            "GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct",
            sample_limit=100  # Small subset for testing
        )
        
        sample_attrs = reader.read_sample_attributes()
        subject_phenos = reader.read_subject_phenotypes()
        protein_coding = reader.read_protein_coding_genes()
        
        print("‚úÖ Data loading successful!")
        print(f"   Expression data: {expression_df.shape}")
        print(f"   Sample attributes: {sample_attrs.shape}")
        print(f"   Subject phenotypes: {subject_phenos.shape}")
        print(f"   Protein coding genes: {len(protein_coding)}")
        
    except FileNotFoundError as e:
        print(f"‚ùå Data files not found: {e}")
        print(f"   Searched in: {reader.data_dir.absolute()}")
        print("\n   Please ensure GTEx data files are available in one of these locations:")
        print("   - data/ (if running from project root)")
        print("   - ../data (if running from new_script/)")
        print("   - Or specify data directory: GTExDataReader(data_dir='path/to/data')")
        print("\n   Required files:")
        print("   - GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct")
        print("   - GTEx_Analysis_v8_Annotations_SampleAttributesDS.tsv") 
        print("   - GTEx_Analysis_v8_Annotations_SubjectPhenotypesDS.tsv")
        print("   - hgnc_complete_set.tsv")
        return False
    
    # 2. Sample Selection
    print("\n2. Selecting samples for analysis...")
    
    # Get available tissues
    available_tissues = reader.get_available_tissues(sample_attrs)
    print(f"   Available tissues: {len(available_tissues)}")
    
    # Select a tissue with enough samples
    tissue_counts = {}
    for tissue in available_tissues[:10]:  # Check first 10 tissues
        samples = reader.get_tissue_samples(sample_attrs, tissue)
        tissue_counts[tissue] = len(samples)
    
    # Choose tissue with most samples
    selected_tissue = max(tissue_counts, key=tissue_counts.get)
    print(f"   Selected tissue: {selected_tissue} ({tissue_counts[selected_tissue]} samples)")
    
    # Get young and old samples for this tissue
    young_samples = reader.filter_samples_by_metadata(
        sample_attrs, subject_phenos,
        min_rin=6.0, age_group='young', tissue=selected_tissue
    )
    
    old_samples = reader.filter_samples_by_metadata(
        sample_attrs, subject_phenos,
        min_rin=6.0, age_group='old', tissue=selected_tissue
    )
    
    print(f"   Young samples: {len(young_samples)}")
    print(f"   Old samples: {len(old_samples)}")
    
    if len(young_samples) < 5 or len(old_samples) < 5:
        print("   ‚ö†Ô∏è  Not enough samples for comparison. Using all available samples.")
        all_samples = expression_df.columns[:50].tolist()  # Use first 50 samples
        young_samples = all_samples[:25]
        old_samples = all_samples[25:]
    
    all_samples = young_samples + old_samples
    
    # 3. Data Preprocessing
    print("\n3. Preprocessing expression data...")
    
    preprocessor = DataPreprocessor()
    
    # Filter expression data to selected samples
    filtered_expression = expression_df[all_samples]
    
    # Run preprocessing pipeline
    processed_df, processing_info = preprocessor.preprocess_expression_data(
        filtered_expression,
        protein_coding,
        apply_log=True,
        filter_low_expr=True,
        filter_low_var=True,
        detect_outliers=True,
        min_expression=0.1,
        min_samples=5,
        min_variance=0.1,
        outlier_contamination=0.05
    )
    
    print("‚úÖ Preprocessing completed!")
    print(f"   Original shape: {processing_info['original_shape']}")
    print(f"   Final shape: {processing_info['final_shape']}")
    print(f"   Steps applied: {processing_info['steps_applied']}")
    
    # 4. Network Analysis
    print("\n4. Building coexpression network...")
    
    network_analyzer = NetworkAnalysis()
    
    # Build network
    network_results = network_analyzer.construct_network(
        processed_df,
        power=None,  # Auto-determine
        min_module_size=10,  # Small for test data
        correlation_method='pearson'
    )
    
    print("‚úÖ Network construction completed!")
    print(f"   Soft threshold power: {network_results['power']}")
    
    # Count modules
    modules = network_results['modules']
    module_counts = pd.Series(modules).value_counts().sort_index()
    n_modules = len(module_counts) - (1 if 0 in module_counts.index else 0)
    print(f"   Number of modules: {n_modules}")
    print(f"   Module sizes: {dict(module_counts.head())}")
    
    # 5. MDC Analysis
    print("\n5. Running MDC analysis...")
    
    mdc_analyzer = MDCAnalyzer()
    
    # Split data by groups
    young_expr = processed_df[[s for s in young_samples if s in processed_df.columns]]
    old_expr = processed_df[[s for s in old_samples if s in processed_df.columns]]
    
    print(f"   Young group: {young_expr.shape[1]} samples")
    print(f"   Old group: {old_expr.shape[1]} samples")
    
    # Run MDC analysis with reduced permutations for testing
    mdc_results = mdc_analyzer.analyze_differential_connectivity(
        young_expr,
        old_expr,
        modules,
        network_results['power'],
        "Young",
        "Old",
        run_permutation_test=True,
        n_permutations=20  # Reduced for testing
    )
    
    print("‚úÖ MDC analysis completed!")
    
    # Show results
    mdc_df = mdc_results['mdc_results']
    print(f"   Modules analyzed: {len(mdc_df)}")
    
    if 'permutation_results' in mdc_results:
        significant = mdc_analyzer.get_significant_modules(p_threshold=0.1)  # Relaxed for testing
        print(f"   Significant modules: {len(significant)}")
        
        if len(significant) > 0:
            print("   Top significant modules:")
            for _, row in significant.head(3).iterrows():
                print(f"     Module {row['module_id']}: log ratio = {row['log_mdc_ratio']:.3f}, p = {row['p_value_corrected']:.3f}")
    
    # 6. Basic Visualization Test
    print("\n6. Testing visualization functions...")
    
    visualizer = NetworkVisualizer()
    
    try:
        # Test power analysis plot
        if network_results['power_analysis'] is not None:
            power_fig = visualizer.plot_power_analysis(network_results['power_analysis'])
            print("   ‚úÖ Power analysis plot created")
        
        # Test module sizes plot
        module_fig = visualizer.plot_module_sizes(modules)
        print("   ‚úÖ Module sizes plot created")
        
        # Test MDC results plot
        mdc_fig = visualizer.plot_mdc_results(mdc_df, "Young", "Old")
        print("   ‚úÖ MDC results plot created")
        
        print("   üìä All visualization functions working!")
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Visualization error: {e}")
    
    print("\n" + "=" * 60)
    print("PIPELINE TEST COMPLETED SUCCESSFULLY! üéâ")
    print("=" * 60)
    print("\nThe analysis pipeline is ready to use.")
    print("You can now run the Streamlit app with:")
    print("  streamlit run streamlit_app.py")
    print("=" * 60)
    
    return True

def test_small_synthetic_data():
    """Test with small synthetic data if GTEx data is not available."""
    
    print("\nüß™ Testing with synthetic data...")
    
    # Create synthetic expression data
    np.random.seed(42)
    n_genes = 200
    n_samples = 40
    
    # Generate correlated gene expression
    expression_data = np.random.normal(5, 2, (n_genes, n_samples))
    
    # Add some correlation structure
    for i in range(0, n_genes, 10):
        # Create modules of 10 genes each
        module_effect = np.random.normal(0, 1, n_samples)
        for j in range(min(10, n_genes - i)):
            expression_data[i + j] += module_effect * 0.5
    
    # Create DataFrames
    gene_ids = [f"GENE_{i:04d}" for i in range(n_genes)]
    sample_ids = [f"SAMPLE_{i:04d}" for i in range(n_samples)]
    
    expression_df = pd.DataFrame(expression_data, index=gene_ids, columns=sample_ids)
    
    # Create two groups
    group1_samples = sample_ids[:20]
    group2_samples = sample_ids[20:]
    
    print(f"   Created synthetic data: {expression_df.shape}")
    
    # Test preprocessing
    preprocessor = DataPreprocessor()
    
    processed_df, _ = preprocessor.preprocess_expression_data(
        expression_df,
        apply_log=False,  # Already in log-like scale
        filter_low_expr=False,
        filter_low_var=True,
        detect_outliers=False,  # Skip for synthetic data
        min_variance=0.01
    )
    
    print(f"   Processed data: {processed_df.shape}")
    
    # Test network analysis
    network_analyzer = NetworkAnalysis()
    
    network_results = network_analyzer.construct_network(
        processed_df,
        power=6,  # Fixed power for synthetic data
        min_module_size=5
    )
    
    modules = network_results['modules']
    n_modules = len(set(modules.values()))
    print(f"   Detected {n_modules} modules")
    
    # Test MDC analysis
    mdc_analyzer = MDCAnalyzer()
    
    group1_expr = processed_df[group1_samples]
    group2_expr = processed_df[group2_samples]
    
    mdc_results = mdc_analyzer.analyze_differential_connectivity(
        group1_expr,
        group2_expr,
        modules,
        6,  # power
        "Group1",
        "Group2",
        run_permutation_test=True,
        n_permutations=10  # Quick test
    )
    
    print("   ‚úÖ Synthetic data test completed!")
    
    return True

if __name__ == "__main__":
    # Try with real data first, fall back to synthetic if needed
    try:
        success = test_pipeline()
    except Exception as e:
        print(f"\n‚ùå Real data test failed: {e}")
        print("Falling back to synthetic data test...")
        success = test_small_synthetic_data()
    
    if success:
        print("\nüéØ All tests passed! The pipeline is ready for use.")
    else:
        print("\n‚ùå Tests failed. Please check the error messages above.")
